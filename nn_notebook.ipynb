{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intuition behing the neural network\n",
    "A simple neural network has three layers the **Input** layer, the **Hidden** layer and the **Output** layer. The input layer is symbolic in the sence that it does nothing other than provide the inputs to the hidden layer. The hidden layer is where most of the learning and computation occur. Adding more hidden layers to a model will increase its depth and make it more powerfull. This the definition of **Deep Learning**, very deep models are capable of processing large datasets with very high accuracy. Large neural networks do have some drawbacks and require more data the bigger they get so using very deep models is not always recomended. The output layer is used to produce the output of the model and works in a similar fasion to the hidden layer, the output can be anything from a classification between cat and dog pictures or the probability of rain in the next day to a prediction of the stock exchange prices.\n",
    "\n",
    "Each layer in the neural network (excluding the input layer) is followed by an **activation function**. This is a **non-linear** function that controls the flow of information through the network. If the activation function were to be linear, i.e. no activation, then the model would simplyfy it self into one big linear function. This would not only make the mutiple hidden layers redundant but also prevent the neural network from learning a non-linear function which is the whole point of using neural networks.\n",
    "\n",
    "Neural networks are trained by optimizing the error between the output and the real data. To calculate this error two functions are used. First, the **loss function** is used to calculate the error between one output and one sample. Second, the **cost function** applies the loss function on all samples in the data. The cost function is used by the **backpropagation** where the gradients of the cost are calculated by taking the derivative of the cost function. These gradients are then used by an **optimizer** to abjust the neural network towards a more correct path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How do the nodes of a neural network look like?\n",
    "Each node in a neural network has two parameters, a weight (W) and a bias (b). The output (Z) of the node is calculated using Equation 1 where x is the input.\n",
    "\n",
    "$$Z = Wx + b \\tag{1}$$\n",
    "\n",
    "The weight selects which of the inputs are more relevant to the model while the bias allows the model to fit better around the data.\n",
    "\n",
    "The value of Z is then given as input to the **activation function**. The default activation function for a neural network is the **sigmoid**; however, there are other more popular alternatives. For example, ReLU or tanh. The sigmoid is defined in Equation 2.\n",
    "\n",
    "$$\\sigma(Z) = \\frac{1}{1+e^{-Z}} \\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loss and Cost functions\n",
    "Choosing the right loss function will depend on the problem at hand as this will heavily influence how the neural networks will be optimized to produce an output. Different tasks require different loss functions; for example, when classifying input between two classes (cats and dogs) the **Logistic Regression** is used but if there are more than two classes then the Softmax function is used instead. However, if the task is to predict a number (temperature) then a function such as the Mean Squared Error should be used.\n",
    "\n",
    "In this example the neural netwok will be using the **Logistic Regression** to classify new data. The loss and cost are shown in Equation 3 and 4, respectively. A more indepth, but optional, explanation for this is geven in the next section.\n",
    "\n",
    "$$L(y, \\hat{y}) = -(y \\log{\\hat{y}} + (1-y) \\log{(1-\\hat{y})}) \\tag{3}$$\n",
    "\n",
    "$$J = \\frac{1}{m}\\sum_{i=1}^mL(y^{(i)}, \\hat{y}^{(i)})\\tag{4}$$\n",
    "\n",
    "where **m** represents the number of samples in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression\n",
    "Logistic regression is used for binary classification which means that the output is either 0 or 1 (two classes). This algorithm has two rules: rule one, if the expected output is 1 the model will try to approximate that with $\\hat{y}$; rule two, if the expected output is 0 then the model will produce $1-\\hat{y}$, the oposit of rule one. This can be written as the probability of y (output) given x (input):\n",
    "\n",
    "$$p(y|x) = \\hat{y}^y (1-\\hat{y})^{1-y} \\tag{5}$$\n",
    "\n",
    "becasue\n",
    "\n",
    "If y = 1 then $p(y|x) = \\hat{y}^1 (1-\\hat{y})^{1-1} = \\hat{y} \\tag{6}$\n",
    "\n",
    "If y = 0 then $p(y|x) = \\hat{y}^0 (1-\\hat{y})^{1-0} = 1-\\hat{y} \\tag{7}$\n",
    "\n",
    "To simplify the computation the natural logarithm is taken. This turns the exponents into multiplication and multiplication into addition while maintaining the same properties of being a strictly monotonically increasing function (as x gets bigger so does y).\n",
    "\n",
    "$$ \\log{p(y|x)} = \\log{\\hat{y}^y (1-\\hat{y})^{1-y}} = \\\\ y\\log{\\hat{y}}+(1-y)\\log{(1-\\hat{y})} \\tag{8}$$\n",
    "\n",
    "Finally, the function is made negative as seen in Equation 3 because the objective is to minimize the error.\n",
    "\n",
    "The cost function simply calculates this error value for all of the samples then takes the average error for the whole data by multiplying the sum by $\\frac{1}{m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizing the neural network using Gradient Decent\n",
    "The objective of the optimizer is to find the global minima of the cost function. In other words, the set of weights and biases that, when used in neural network, produce the smallest possible error. There are multiple optimizer algorithms that are very powerful (Adam, RMSprop, SGD) but this example will use the most basic one **Gradien Decent**.\n",
    "\n",
    "The weights and biases of a neural networks create a search space where the objactive of the optimizer is to move through it searching for the best combination.\n",
    "\n",
    "Gradient Decent uses the derivative of the cost function to find the slope (gradient) of the current weights and biases. This slope is then used to determine the direction in which the optimizer moves towards the global minima. The **learnin rate**, represented as $\\alpha$, controlls how fast the optimizer moves through the search space.\n",
    "\n",
    "The weights and biases are updated using the formulas below which are applied to each node in the neural network. The derivative of the cost function is covered in the **Backpropagation** section.\n",
    "\n",
    "Updating the weights:\n",
    "\n",
    "$$W = W  - \\alpha \\frac{\\partial J(W, b)}{\\partial W} \\tag{9}$$\n",
    "\n",
    "Updating the biases:\n",
    "\n",
    "$$b = b  - \\alpha \\frac{\\partial J(W, b)}{\\partial b} \\tag{10}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Backpropagation\n",
    "Backproagation is the algorithm used to calculate the gradients of the cost function. Becasue of this, it involves calculating the derivatives for the functions used in the neural network. However, any modern deep learning frame work will compute these automatically from the loss function defined, or chosen, by the user.\n",
    "\n",
    "Lets define a neural network with a single node that uses Logistic Regression for binary classification. In this example the **activation function** is denoted as **a** which also represents the output of the model, previously denoted as $\\hat{y}$.\n",
    "\n",
    "$$(x, W, b) \\longrightarrow Z(x) = Wx+b \\longrightarrow a = \\sigma(Z) \\longrightarrow L(a, y)$$\n",
    "\n",
    "To apply **gradient descent** the derivative of J must be taken with respect to W and b. Backpropagation works in reverse, so the first derivative taken is the **loss function**, then the **activation function**, next the node Z and, finally,  the weights and biases.\n",
    "\n",
    "First, the derivative of the **Logistic Regression** function shows how the **activation function** affects the **loss**.\n",
    "\n",
    "$$L(y, a) = -(y \\log{a} + (1-y) \\log{(1-a)}) \\\\\n",
    "\\frac{dL}{da}=-\\left(y\\frac{1}{a}+(1-y)\\frac{1}{1-a}-1\\right) \\\\\n",
    "\\frac{dL}{da}=-\\frac{y}{a}+\\frac{1-y}{1-a} \\\\\n",
    "\\frac{dL}{da}=\\frac{-y+ya+a-ya}{a(1-a)} \\\\\n",
    "\\frac{dL}{da}=\\frac{a-y}{a(1-a)} \\tag{11}$$\n",
    "\n",
    "In the second line of equation 11 the **Chain Rule** was used to get the derivative of $\\log{(1-a)}$.\n",
    "\n",
    "Second, the derivative of the activation function is taken in terms of Z. In this example the **sigmoid** is used in the activation, its derivative is shown in Equation 12 and the calculation on how to get there can be found by clicking [here](https://math.stackexchange.com/q/78575/725303).\n",
    "\n",
    "$$\\frac{d\\sigma(Z)}{dZ}=\\sigma(Z)(1-\\sigma(Z)) \\tag{12}$$\n",
    "\n",
    "Becasue $\\sigma(Z)$ is represented as **a** this derivative can be expressed as:\n",
    "\n",
    "$$\\frac{da}{dZ}=a(1-a)) \\tag{13}$$\n",
    "\n",
    "Third, the derivative of the loss in respect to Z is shown in Equation 13. This also uses the Chain Rule by multiplying the derivatives calculated in the last two steps (Equations 11 and 13).\n",
    "\n",
    "$$\\frac{dL}{dZ} = \\frac{dL}{da}\\frac{da}{dZ} = \\frac{a-y}{a(1-a)}a(1-a))= a-y \\tag{14}$$\n",
    "\n",
    "Fourth, the derivatives for the weights and biases are calculated as follows:\n",
    "\n",
    "Weights:\n",
    "$$\\frac{dL}{dW}=\\frac{dL}{dZ}\\frac{dZ}{dW}=(a-y)x \\tag{15}$$\n",
    "because $\\frac{dZ}{dW}=x$\n",
    "\n",
    "Biases:\n",
    "$$\\frac{dL}{db}=\\frac{dL}{dZ}\\frac{dZ}{db}=(a-y) \\tag{16}$$\n",
    "because $\\frac{dZ}{db}=1$\n",
    "\n",
    "Finaly, to put every thing into the context of the cost function as required by the gradient decent all that is required is to take the sum of all gradients for each sample and average the result.\n",
    "\n",
    "$$ \\frac{\\partial J(W,b)}{\\partial W}=\\frac{1}{m}\\sum_{i=1}^m \\frac{\\partial L(a^{(i)}, y^{(i)})}{\\partial W} \\tag{17}$$\n",
    "\n",
    "Equation 17 shows how to calculate the derivative for the weights; however, to calculate it for  the bias simply change $\\partial W$ to $\\partial b$. Note that the derivative in the summation is the same as Equation 15 (or 16) applied to each sample in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Creating a neural network\n",
    "\n",
    "### 7.1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Initialize parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Foreward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 Training the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8 Making predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
